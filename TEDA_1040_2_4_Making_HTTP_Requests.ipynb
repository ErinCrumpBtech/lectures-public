{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 2.4 Making HTTP Requests\n",
        "As seen in the previous reading, HTTP requests are used to access data from servers. HTTP requests are extremely important for pulling data into Python code so that it can be processed and used in data analytics projects. In this reading, you will learn how to make HTTP requests using Python.\n",
        "\n",
        "## Making a simple GET request\n",
        "Recall that there are several types of HTTP requests and that the GET request is the most common of all. GET requests are used to *get* information from a server and usually do not require authentication (ie. a user to be logged in).\n",
        "\n",
        "The easiest way to make a GET request is to just open up a new tab in your internet browser and type in a URL. Let's try using the website [https://www.scrapethissite.com/pages/simple/](https://www.scrapethissite.com/pages/simple/), which returns a simple HTML page of countries of the world.\n",
        "\n",
        "âœ… **Try it out**: Open up a new tab in your browser and go to the link shown above.\n",
        "\n",
        "You've probably done it a million times before, but by going to the link shown above, you made a GET request. As you can see by opening it up in your web browser, the web site is just a bunch of HTML code lumped together. However, all of that HTML has a bunch of data that can be extracted into a data structure and analyzed.\n",
        "\n",
        "## Making a GET request with Python\n",
        "Web browsers make it really easy to make GET requests. You just type in a web address, hit Enter, and the HTML gets returned to your browser. However, Python can also send HTTP requests using the `requests` package. This package does the exact same thing as your web browser, except that it doesn't render the formatted page to the screen.\n",
        "\n",
        "Let's try it out. First, we import the `requests` library."
      ],
      "metadata": {
        "id": "wzgl8vJY2Mpu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_lJXvKi2FoE"
      },
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we can use the `.get()` function from the `requests` library to make a GET request to the URL specified inside of the parentheses."
      ],
      "metadata": {
        "id": "Atn_jKuO4Y7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "requests.get('https://www.scrapethissite.com/pages/simple/')"
      ],
      "metadata": {
        "id": "NiELAef-4Yte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see above, the code sent a GET request to the web address provided and then returned a response code. A response code of 200 indicates a success, while other response codes like 404 indicate errors (ie. Page not found).\n",
        "\n",
        "To get the HTML out of the response, we can simply add the property `.text` to the end of the GET request."
      ],
      "metadata": {
        "id": "nV5d5xUB4jSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "requests.get('https://www.scrapethissite.com/pages/simple/').text"
      ],
      "metadata": {
        "id": "WtvH8IeX4XHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see above, the text returned by the GET request is just a bunch of HTML code. A web browser could interpret this HTML code and make it visually appealing on the screen, but in Python, the HTML is just plain text.\n",
        "\n",
        "Finally, we can save the HTML returned from the GET request into a variable. Storing the text into a variable means that the code won't have to keep sending a GET request every time the HTML code is desired, which could make running the web scraper run more slowly because it has to send requests over and over again."
      ],
      "metadata": {
        "id": "j430bNpF4-dO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get('https://www.scrapethissite.com/pages/simple/').text"
      ],
      "metadata": {
        "id": "harnyg_M42IM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other kinds of requests\n",
        "Although less common with web scrapers, the `requests` package also supports other HTTP request types such as POST, PUT, and DELETE. Additionally, each request type allows the user to specify a variety of different factors including login information (if the page requires it), tokens (another way of authenticating), and query parameters. The specific parameters used in each web scraper will vary immensly, so it's best to research how to input the parameters into the function as needed.\n",
        "\n",
        "This has been a short explanation of how to perform HTTP requests in Python. In the next reading, you will learn how to parse through the HTML code returned from the `requests` package using the parsing library `BeautifulSoup`."
      ],
      "metadata": {
        "id": "HGpAta6_59KI"
      }
    }
  ]
}